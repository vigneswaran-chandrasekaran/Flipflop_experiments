{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e44g5kTMZqgf"
      },
      "source": [
        "## Shakespear-like poem generation on character level\n",
        "\n",
        "##### Flipflop vs LSTM comparison\n",
        "\n",
        "\n",
        "Code taken from: \n",
        "[Tensorflow documentation on RNN](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/13YaGMPsmJ4MNgE3cKcUjOws31PRCC9Km/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcygKkEVZBaa"
      },
      "source": [
        "Some samples of data\n",
        "<pre>\n",
        "QUEENE:\n",
        "I had thought thou hadst a Roman; for the oracle,\n",
        "Thus by All bids the man against the word,\n",
        "Which are so weak of care, by old care done;\n",
        "Your children were in your holy love,\n",
        "And the precipitation through the bleeding throne.\n",
        "\n",
        "BISHOP OF ELY:\n",
        "Marry, and will, my lord, to weep in such a one were prettiest;\n",
        "Yet now I was adopted heir\n",
        "Of the world's lamentable day,\n",
        "To watch the next way with his father with his face?\n",
        "\n",
        "ESCALUS:\n",
        "The cause why then we are all resolved more sons.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense, RNN\n",
        "from tensorflow.keras.activations import tanh\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHDoRoc5PKWz"
      },
      "source": [
        "##### Download the Shakespeare dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_55cOxLkAb"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavnuByVymwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d449ad9b-277a-4fd7-f446-6b687bc40e50"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a86OoYtO01go"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s4f1q3iqY8f"
      },
      "source": [
        "Now create the `preprocessing.StringLookup` layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmX_jbgQqfOi"
      },
      "source": [
        "It converts form tokens to character IDs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLv5Q_2TC2pc"
      },
      "source": [
        "ids = ids_from_chars(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2m3mqkDjRj"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqTDDxS-s-H8"
      },
      "source": [
        "This layer recovers the characters from the vectors of IDs, and returns them as a `tf.RaggedTensor` of characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2GCh0ySD44s"
      },
      "source": [
        "chars = chars_from_ids(ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FeW5gqutT3o"
      },
      "source": [
        "You can `tf.strings.reduce_join` to join the characters back into strings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxYI-PeltqKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef4fbd0-de4d-464a-9b19-62c8485768ea"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UopbsKi88tm5"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmxrYDCTy-eL"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjH5v45-yqqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2e230b-e2c3-419a-e4ce-b3ef32f61cc2"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-G2oaTxy6km"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "The `batch` method lets you easily convert these individual characters to sequences of the desired size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3d6b03-131c-4742-d02d-d8dcc9e24256"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PHW902-4oZt"
      },
      "source": [
        "It's easier to see what this is doing if you join the tokens back into strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO32cMWu4a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8c218a-09be-4e98-bed8-d82a7a61d755"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb8afd2-744d-4b48-da3f-0fe594d22801"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc18eed-8a9b-42e8-92f3-e8544b6297b3"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1743e5f8-3f04-40ab-d761-46803ec1a8eb"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((512, 100), (512, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "#### Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B9-8DhHytYg",
        "outputId": "3e5fc770-3129-48bf-a47c-7869de44312e"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.117.135.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.117.135.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.117.135.194:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.117.135.194:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "source": [
        "class LSTM_model(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = tf.keras.layers.LSTM(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.rnn.get_initial_state(x)\n",
        "    x, h, c = self.rnn(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, [h,c]\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkopmlAu0Ftd"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDZ4DMqr0BA1",
        "outputId": "64f3637e-766b-45ce-fe50-04d88695b302"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "EPOCHS = 100\n",
        "\n",
        "with strategy.scope():\n",
        "  lstm_model = LSTM_model(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "  for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = lstm_model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "  adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "  lstm_model.compile(optimizer=adam, loss=loss)\n",
        "  lstm_history = lstm_model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 100, 66) # (batch_size, sequence_length, vocab_size)\n",
            "Epoch 1/100\n",
            "21/21 [==============================] - 6s 53ms/step - loss: 4.8774\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 3.4139\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 2.9872\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 2.6231\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 2.4268\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 2.3081\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 2.2244\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 2.1526\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 2.0866\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 2.0286\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.9783\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.9402\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.8988\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.8720\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.8262\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.7960\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.7636\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.7392\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.7182\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.6978\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.6758\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.6579\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.6446\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.6244\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.6097\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.5938\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.5822\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.5709\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.5605\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.5518\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.5387\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.5288\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.5195\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.5134\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 2s 54ms/step - loss: 1.5062\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4951\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4903\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4809\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4761\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4695\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4630\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4520\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4500\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4420\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4393\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4363\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4276\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4234\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4165\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.4159\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4083\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 2s 54ms/step - loss: 1.4025\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.4022\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3981\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3965\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3857\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3848\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3817\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3774\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3726\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3658\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3656\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3615\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3533\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3530\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3545\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3488\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3445\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3389\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3425\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3369\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3320\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3284\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3258\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3270\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3192\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3146\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3124\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3136\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3063\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3059\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.3045\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2990\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3033\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.3011\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.2942\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2911\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2895\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.2905\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2841\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.2826\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2796\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.2768\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2742\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2692\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.2719\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.2698\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 2s 54ms/step - loss: 1.2696\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 2s 52ms/step - loss: 1.2648\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 2s 53ms/step - loss: 1.2583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f620b2-dc1a-4403-f4dc-c21cc70e5c1c"
      },
      "source": [
        "lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"lstm_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      multiple                  16896     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                multiple                  5246976   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             multiple                  67650     \n",
            "=================================================================\n",
            "Total params: 5,331,522\n",
            "Trainable params: 5,331,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM1Vbxs_URw5"
      },
      "source": [
        "This gives us, at each timestep, a prediction of the next character index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c5a629-1573-454d-aa99-0690fc0118cf"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([25, 20, 50, 31, 50, 33, 27, 40,  7,  7, 51,  4, 53, 27, 44, 53, 13,\n",
              "       33, 40, 52, 29, 57, 58, 13, 45, 13, 23, 58, 17, 36, 20, 15, 42, 25,\n",
              "       35, 45, 61,  9, 53, 54,  2, 18, 64, 48, 14, 24, 58, 13, 37, 30, 19,\n",
              "        6, 36,  7, 50,  3,  4,  0, 54, 24, 53, 25, 34, 19, 61, 20, 14, 63,\n",
              "       26, 15, 52, 38, 56, 29, 32, 24, 36,  5, 45, 34,  9, 58, 49, 61, 20,\n",
              "       38,  3, 20, 23, 35, 54, 25,  3, 16, 44,  0, 63, 31, 60, 59])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "#### Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSBU1tHmlUSs"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMOuDutnOxK"
      },
      "source": [
        "lstm_one_step_model = OneStep(lstm_model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLu7Y8UCMT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b2ed6c-5147-4a3c-b807-e6a175819c40"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = lstm_one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "As his hell and false Edward up the city.\n",
            "This is the lettles will do growly repair.\n",
            "Your gracious lords, woe poin a father,\n",
            "Your trial off have done enmity: it is:\n",
            "Thus did I seek for this affections to me;\n",
            "For one show found his grave is little sprintly.\n",
            "Here lives a man,\n",
            "Though you have learn'd it-off,' ten times does\n",
            "Against the doubled another house,\n",
            "That clost his inching youth: my goes may speak\n",
            "Awayers: abids, Signior York!\n",
            "Offer my services have fall'd moon he kiss\n",
            "'The issue without the thirds of enemiase\n",
            "That raised me to keep you finder\n",
            "As may we saw him friendly prayded;\n",
            "Mine state was too our deflory.\n",
            "\n",
            "Second Musician:\n",
            "Pats I here's over have stretch'd your country's arms;\n",
            "Before: trembling one, so light,\n",
            "And am the scapes of teempe, my bed, flower:\n",
            "but I; all thesen blows not wondering.\n",
            "\n",
            "LARTIUS:\n",
            "So shall I give; my lord; the people's true, o\n",
            "wast, fortune, fire, not for thy peace. Blossed, all; poor life,\n",
            "Maybe; for, I'll be with you: he majest,\n",
            "The provend on a humour \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 11.484649658203125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxoWW3LCe780"
      },
      "source": [
        "With flipflop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k18YHN0sga1t"
      },
      "source": [
        "class FF(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super(FF, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        self.j_h = keras.layers.Dense(self.units)\n",
        "        self.j_x = keras.layers.Dense(self.units)\n",
        "        self.k_h = keras.layers.Dense(self.units)\n",
        "        self.k_x = keras.layers.Dense(self.units)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "        j = tf.sigmoid(self.j_x(inputs) + self.j_h(prev_output))\n",
        "        k = tf.sigmoid(self.k_x(inputs) + self.k_h(prev_output))\n",
        "        output = j * (1 - prev_output) + (1 - k) * prev_output\n",
        "        return output, [output]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2VWnl5Te688"
      },
      "source": [
        "class FF_model(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = tf.keras.layers.RNN(FF(rnn_units),\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.rnn.get_initial_state(x)\n",
        "    x, states = self.rnn(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhNiEMQefMGc",
        "outputId": "7c6594f2-f182-483b-fcce-3233ecdc8855"
      },
      "source": [
        "with strategy.scope():\n",
        "  ff_model = FF_model(\n",
        "      # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "      vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "      embedding_dim=embedding_dim,\n",
        "      rnn_units=rnn_units)\n",
        "  for input_example_batch, target_example_batch in dataset.take(1):\n",
        "      example_batch_predictions = ff_model(input_example_batch)\n",
        "      print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "  print(ff_model.summary())\n",
        "  adam = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "  ff_model.compile(optimizer='adam', loss=loss)\n",
        "  ff_history = ff_model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(512, 100, 66) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"ff_model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      multiple                  16896     \n",
            "_________________________________________________________________\n",
            "rnn_1 (RNN)                  multiple                  2625536   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             multiple                  67650     \n",
            "=================================================================\n",
            "Total params: 2,710,082\n",
            "Trainable params: 2,710,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "21/21 [==============================] - 5s 40ms/step - loss: 3.5585\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 3.1889\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.9339\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.6787\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.4849\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.3779\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.3147\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.2570\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 2.2050\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.1580\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.1107\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 2.0706\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 2.0320\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.9955\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.9610\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.9268\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.8940\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.8677\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.8386\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.8132\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.7843\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.7597\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.7349\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.7148\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.6938\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.6725\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.6587\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.6384\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.6200\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.6071\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.5900\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.5764\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.5635\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.5512\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.5383\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.5281\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.5149\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.5103\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.4955\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.4888\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.4789\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.4687\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.4631\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.4504\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.4440\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.4372\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 2s 41ms/step - loss: 1.4311\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.4269\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.4166\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.4091\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.4011\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3952\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.3884\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3846\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3775\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.3719\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3665\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3624\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3583\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 2s 41ms/step - loss: 1.3533\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3467\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3437\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.3419\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3339\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3289\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3230\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3195\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3111\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3133\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.3064\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2999\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2970\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2953\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.2896\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2868\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.2824\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2795\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2760\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2716\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2687\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2635\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2590\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.2552\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2531\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2508\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2481\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2434\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2396\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2388\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 2s 41ms/step - loss: 1.2325\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2288\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2276\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2272\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2223\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2192\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2193\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2119\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 2s 39ms/step - loss: 1.2083\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.2054\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 2s 40ms/step - loss: 1.1998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40BcWhpnf4wO"
      },
      "source": [
        "ff_one_step_model = OneStep(ff_model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GEPXwLZf_2w",
        "outputId": "de9975ef-3eb5-4318-8e17-286ee01eab91"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = ff_one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Is not it! Voluble; give your general saint;\n",
            "She were all: this is come brush'd alove,\n",
            "And traitor him for rude, that back again; yet sure,\n",
            "Yet a mind bid me with repity here.\n",
            "\n",
            "RICHOOS:\n",
            "I have becamed done, as you perchance and tell thereof,\n",
            "Both in the beggar hate, conlein on thy brother:\n",
            "Yet beggar to the faith, yet he, as he' whom was\n",
            "That I, unreasons, with a leave, and blunt goodly.\n",
            "\n",
            "KING EDWARD IV:\n",
            "Now it that violent cuttain\n",
            "Presence; and weigh affection,\n",
            "His troth?--'tod God, I!\n",
            "Shall I am never speak, that I have gone.\n",
            "\n",
            "Ventious,\n",
            "She have is lates of that say the cincer:\n",
            "Under the sortuness joy is fooler;\n",
            "And rather mother from the banish.\n",
            "Very go twal liberty, who comest thou\n",
            "deny to and time, and soil-whum doublied mine.\n",
            "Because hath he shall have entertatching dam\n",
            "Our pace of darmward in govern wing\n",
            "Of fly.\n",
            "\n",
            "First Keeper: I willow'd with chamber, to been the people.\n",
            "Call, not breathed more authority to with some\n",
            "jefty malice; thou art dangerous are not news\n",
            "Is news Petruch \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 8.352195978164673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkAi25BR5gjo"
      },
      "source": [
        "Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "TJ7J0m9b5jj9",
        "outputId": "4d831f41-26bf-428d-c181-c5f3189a4bc0"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(ff_history.history['loss'], label='FF loss')\n",
        "plt.plot(lstm_history.history['loss'], label='LSTM loss')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training loss\")\n",
        "plt.title(\"Training loss - FF vs LSTM\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN23_Njs6T-u"
      },
      "source": [
        "#save models\n",
        "lstm_one_step_model.save_weights('lstm_one_step/checkpoint')\n",
        "ff_one_step_model.save_weights('ff_one_step/checkpoint')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "shakespear_text_gen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}